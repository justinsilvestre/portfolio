import {
  HanlibKaeriten,
  HanlibKaeritenToKakikudashibun,
  HanlibKakikudashibun,
  HanlibGlossingLanguage,
  HanlibGlossEditingUi,
} from "./imports/hanlib";

## A glossing language inspired by _kanbun kundoku_

To deal with the difficulties in interpreting Classical Chinese, Japanese speakers developed a sophisticated **glossing tradition called _kanbun kundoku_**. In this tradition, students are taught to take Classical Chinese sentences and **systematically transform them step by step into word-for-word Japanese translations**. The resulting translations are not perfectly idiomatic Japanese, but they do not aim to be. Rather, they are a way to bridge the gap between the syntactic differences separating Classical Chinese and Japanese. The glosses in Hanlib take after this tradition, as a means of helping English-speaking readers to engage with Classical Chinese texts.

<HanlibKaeriten />
<HanlibKaeritenToKakikudashibun />

The glossing language at the heart of Hanlib is modeled after the rich annotation system in _kanbun kundoku_, in which texts are marked with grammatical and lexical information as an aid to producing word-for-word translations. The most important of these is **a system of annotations for marking changes in word order**, called 返り点 _kaeriten_. By marking just a few characters in a Chinese sentence with _kaeriten_ marks, it's possible to notate the exact word order of a corresponding Japanese translation. More than just a translation aid, these _kaeriten_ word-order marks are in effect a concise formal language for encoding syntactic information about a Chinese text.

<HanlibKakikudashibun />

Since Japanese shares the Chinese characters with Classical Chinese, the difference between a text in Chinese modified to fit Japanese word order and a text in grammatical Japanese is surprisingly small. In the vast majority of cases, the only difference is the addition of a few grammatical endings and particles. When a word-for-word translation is produced in this way, the result is called a 書き下し文 _kakikudashibun_. Though this is a kind of translation, the _kakikudashibun_ is not a translation in the ordinary sense&mdash;its purpose is **to facilitate engagement with the original text**. When Japanese speakers read a Classical Chinese text aloud, the convention is to vocalize a _kakikudashibun_ rendering, and to disregard the original word order (not to mention pronunciation) of the Chinese text, almost as though the _kakikudashibun_ were latent in the original text itself.

This glossing tradition developed in a time when texts were transmitted by hand or in print, and specifically for the needs of Japanese readers of Classical Chinese. But there is nothing stopping us from taking some principles from the _kanbun kundoku_ tradition and applying them to the needs of modern readers of Classical Chinese in other languages. We can **rely on glosses as a gateway to the original text**, rather than a proxy or replacement for it. We can **rely on rich annotations** of Classical Chinese texts as a way of **systematically transforming texts into word-for-word translations**. But instead of manually producing those word-for-word translations (or leaving them to the reader to produce), we can **use software to automatically generate translations** from annotated texts.

<HanlibGlossingLanguage />

This is how I came up with the idea for the glossing language that powers Hanlib. This Hanlib glossing language allows you to specify in plain text the **word-order rearrangements** and **grammatical endings/particles** that are needed to produce a word-for-word translation of a Classical Chinese text into English (or theoretically any other language that uses similar spacing and punctuation). It works through a parser built using the Peggy parser generator for JavaScript. I have yet to document the syntax of the language in detail, but you can see an illustration of the glossing process in the figure to the left, and you can see [the grammar on Github](https://github.com/justinsilvestre/hanlib/blob/main/glossParser/glossGrammar.pegjs), as well as some [test cases](https://github.com/justinsilvestre/hanlib/blob/main/glossParser/src/parseGloss.test.ts) that illustrate its use.

As you can see from the short length of the grammar file, it's a relatively simple language. It is based on a very simple set of principles inherited from the _kanbun kundoku_ tradition. But in combination with the other components of the Hanlib system, it facilitates the automatic generation of a richly interactive Chinese glossed text. Since the Hanlib glossing language records changes in word order in a way similar to the _kaeriten_ marks of the _kanbun kundoku_ tradition, the glosses produced allow readers to hover their mouse over any Chinese word and <strong>instantly see exactly how it corresponds to a word in grammatical English translation</strong>, and vice versa. Users thus gain the same benefit of a text annotated in the _kanbun kundoku_ style, without having to learn any of the complexities of the _kaeriten_ system.

Another goal I had in mind when conceiving of Hanlib was to produce a bilingual lexicon of Classical Chinese and English. Thus,
the Hanlib glossing language is also designed to allow for the automatic extraction of a bilingual lexicon from any corpus of glossed texts. But such a lexicon can serve not only as a helpful source for looking up the translations of words, but also as a way **to see words used in real Chinese texts**, since those texts are the ultimate source of the lexicon data.
To ensure that the popover dictionary feature of the Hanlib UI has solid basis in terms of both its dictionary definitions and example sentences, my current priority is to produce glosses from an introductory Classical Chinese textbook in the public domain, _Introduction to Literary Chinese_ by J. Brandt. After having transcribed the text from the book, I've been gradually working through the Chinese passages to test out the glossing language and the Hanlib UI.

<HanlibGlossEditingUi />

Like Hanlib as a whole, the Hanlib glossing language is still a work in progress. It could use some refinement for edge cases, and I have a number of ideas for making it easier to produce well-formed glosses (via e.g. a graphical user interface). But the core functionality for building out the library of texts and the bilingual lexicon is already in place. Once the introductory glosses are complete, my focus will shift to producing glosses of classic texts, which will hopefully make the dictionary more robust as time goes on and more texts are added. Eventually, I'd like to open up the production of interactive glosses to the public, so that anyone can produce glosses of any Classical Chinese text they like, and the dictionary can take on a life of its own as a community project. I'm optimistic that this will be possible, as I already have had a few people volunteer to help with some aspects of the project, like the multilingual phonetic transcriptions feature. There are lots of people out there like me who are interested in Classical Chinese and recognize the sore need for better tools for learning the language and engaging with real Chinese texts.

It's exciting to think about the potential for further developments if Hanlib succeeds as a community project. Given a high enough volume of glossed texts, it would even be possible to train a machine learning model to produce glosses automatically. Of course, that's a long way off, but it's a possibility I'll be keeping in mind as I continue to develop the project.
